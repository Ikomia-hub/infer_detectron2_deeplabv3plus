from infer_detectron2_deeplabv3plus import update_path
from ikomia import core, dataprocess
import copy
from detectron2.checkpoint import DetectionCheckpointer
from detectron2.config import CfgNode, get_cfg
from detectron2.modeling import build_model
from detectron2.projects.deeplab.config import add_deeplab_config
from detectron2.projects.deeplab.resnet import build_resnet_deeplab_backbone
from torchvision.transforms import Resize
import torch
import numpy as np
import random
import os


# --------------------
# - Class to handle the process parameters
# - Inherits PyCore.CProtocolTaskParam from Ikomia API
# --------------------
class Deeplabv3plusParam(core.CWorkflowTaskParam):

    def __init__(self):
        core.CWorkflowTaskParam.__init__(self)
        # Place default value initialization here
        self.configFile = ""
        self.modelFile = ""
        self.dataset = "Cityscapes"

    def setParamMap(self, param_map):
        # Set parameters values from Ikomia application
        # Parameters values are stored as string and accessible like a python dict
        self.configFile = param_map["configFile"]
        self.modelFile = param_map["modelFile"]
        self.dataset = param_map["dataset"]
        pass

    def getParamMap(self):
        # Send parameters values to Ikomia application
        # Create the specific dict structure (string container)
        param_map = core.ParamMap()
        param_map["configFile"] = self.configFile
        param_map["modelFile"] = self.modelFile
        param_map["dataset"] = self.dataset
        return param_map


# --------------------
# - Class which implements the process
# - Inherits PyCore.CProtocolTask or derived from Ikomia API
# --------------------
class DeepLabv3plus(dataprocess.C2dImageTask):

    def __init__(self, name, param):
        dataprocess.C2dImageTask.__init__(self, name)

        # add output + set data type
        self.addOutput(dataprocess.CSemanticSegIO())
        self.model = None
        self.cfg = None
        self.colors = None
        self.dataset = ""
        self.update = False
        self.classes = None

        # Create parameters class
        if param is None:
            self.setParam(Deeplabv3plusParam())
        else:
            self.setParam(copy.deepcopy(param))

    def getProgressSteps(self):
        # Function returning the number of progress steps for this process
        # This is handled by the main progress bar of Ikomia application
        return 1

    def run(self):
        # Core function of your process
        # Call beginTaskRun for initialization
        self.beginTaskRun()
        # we use seed to keep the same color for our masks + boxes + labels (same random each time)
        random.seed(10)
        # Get input :
        img_input = self.getInput(0)
        src_image = img_input.getImage()

        # Get output :
        semantic_output = self.getOutput(1)

        # Get parameters :
        param = self.getParam()

        # Config file and model file needed are in the output folder generated by the train plugin
        if (self.cfg is None or param.update) and param.configFile != "":
            with open(param.configFile, 'r') as file:
                cfg_data = file.read()
                self.cfg = CfgNode.load_cfg(cfg_data)
                self.classes = self.cfg.CLASS_NAMES
                add_deeplab_config(self.cfg)

        if self.model is None or param.update:
            if param.dataset == "Cityscapes":
                url = "https://dl.fbaipublicfiles.com/detectron2/DeepLab/Cityscapes-" \
                      "SemanticSegmentation/deeplab_v3_plus_R_103_os16_mg124_poly_90k_bs16/" \
                      "28054032/model_final_a8a355.pkl"
                self.cfg = get_cfg()
                cfg_file = os.path.join(os.path.dirname(__file__),
                                        os.path.join("configs", "deeplab_v3_plus_R_103_os16_mg124_poly_90k_bs16.yaml"))
                add_deeplab_config(self.cfg)
                self.cfg.merge_from_file(cfg_file)
                self.cfg.MODEL.WEIGHTS = url

                self.classes = ['road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',
                                'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck',
                                'bus', 'train', 'motorcycle', 'bicycle']

            elif self.cfg is not None:
                self.cfg.MODEL.WEIGHTS = param.modelFile

            if not torch.cuda.is_available():
                self.cfg.MODEL.DEVICE = "cpu"
                self.cfg.MODEL.RESNETS.NORM = "BN"
                self.cfg.MODEL.SEM_SEG_HEAD.NORM = "BN"

            self.model = build_model(self.cfg)
            DetectionCheckpointer(self.model).load(self.cfg.MODEL.WEIGHTS)
            self.model.eval()

        if self.model is not None and src_image is not None:
            # Convert numpy image to detectron2 input format
            input = {}
            h, w, c = np.shape(src_image)
            input["image"] = (torch.tensor(src_image).permute(2, 0, 1))

            if param.dataset == "Cityscapes":
                input["image"] = Resize([512, 1024])(input["image"])

            input["height"] = h
            input["width"] = w

            # Inference with pretrained model
            with torch.no_grad():
                pred = self.model([input])
                pred = pred[0]["sem_seg"].cpu().numpy()

            # Convert logits to labelled image
            dst_image = (np.argmax(pred, axis=0)).astype(dtype=np.uint8)
            # Set image of input/output (numpy array):
            # dstImage +1 because value 0 is for background but no background here
            semantic_output.setMask(dst_image)

            # Create random color map
            if self.colors is None or param.update:
                n = len(self.classes)
                self.colors = []
                for i in range(n):
                    self.colors.append([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)])

                # Apply color map on labelled image
                self.setOutputColorMap(0, 1, self.colors)

            semantic_output.setClassNames(self.classes, self.colors)
            self.forwardInputImage(0, 0)
            param.update = False

        # Step progress bar:
        self.emitStepProgress()

        # Call endTaskRun to finalize process
        self.endTaskRun()


# --------------------
# - Factory class to build process object
# - Inherits PyDataProcess.CProcessFactory from Ikomia API
# --------------------
class Deeplabv3plusFactory(dataprocess.CTaskFactory):

    def __init__(self):
        dataprocess.CTaskFactory.__init__(self)
        # Set process information as string here
        self.info.name = "infer_detectron2_deeplabv3plus"
        self.info.shortDescription = "DeepLabv3+ inference model of Detectron2 for semantic segmentation."
        self.info.description = "Implementation from Detectron2 (Facebook Research). " \
                                "This Ikomia plugin can make inference of pre-trained model from " \
                                "a given config file and a weight file produced by the Ikomia " \
                                "plugin Detectron2_DeepLabV3Plus_Train."
        self.info.authors = "Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, Hartwig Adam"
        # relative path -> as displayed in Ikomia application process tree
        self.info.path = "Plugins/Python/Segmentation"
        self.info.version = "1.1.0"
        self.info.iconPath = "icons/detectron2.png"
        self.info.article = "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"
        self.info.journal = "ECCV 2018"
        self.info.year = 2018
        self.info.license = "Apache-2.0 License"
        # URL of documentation
        self.info.documentationLink = "https://detectron2.readthedocs.io/index.html"
        # Code source repository
        self.info.repository = "https://github.com/facebookresearch/detectron2"
        # Keywords used for search
        self.info.keywords = "semantic, segmentation, detectron2, facebook, atrous, convolution, encoder, decoder"

    def create(self, param=None):
        # Create process object
        return DeepLabv3plus(self.info.name, param)
